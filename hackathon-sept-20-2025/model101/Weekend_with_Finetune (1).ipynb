{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HbKDS2US2cPZ"
      },
      "outputs": [],
      "source": [
        "# @title Installation\n",
        "import re\n",
        "import torch; v = re.match(r\"[0-9\\.]{3,}\", str(torch.__version__)).group(0)\n",
        "xformers = \"xformers==\" + (\"0.0.32.post2\" if v == \"2.8.0\" else \"0.0.29.post3\")\n",
        "!pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
        "!pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "!pip install --no-deps unsloth\n",
        "!pip install transformers==4.55.4\n",
        "!pip install --no-deps trl==0.22.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Importing all needed libraries\n",
        "from unsloth import FastLanguageModel\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from unsloth import is_bfloat16_supported"
      ],
      "metadata": {
        "id": "7XRR_54v2sgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Initializing main part\n",
        "# The imdb dataset is for binary classification (positive/negative),\n",
        "# so we need to set num_labels to 2.\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"distilbert/distilbert-base-uncased\",\n",
        "    auto_model=AutoModelForSequenceClassification,\n",
        "    max_seq_length=512,  # Max sequence length for DistilBert\n",
        "    dtype=None,\n",
        "    num_labels=2,  # Corrected from 6 to 2 for IMDb\n",
        "    full_finetuning=True,\n",
        "    load_in_4bit=True,\n",
        ")\n",
        "\n",
        "# Add LoRA adapters\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,  # Low-rank adaptation rank\n",
        "    target_modules=[\"q_lin\", \"v_lin\"],  # For DistilBert\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=True,\n",
        ")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VcI5_hUa2tdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Supporting Functions and Dataset\n",
        "\n",
        "# Load simple dataset\n",
        "dataset = load_dataset(\"imdb\", split=\"train[:1000]\")\n",
        "\n",
        "# Format the dataset correctly\n",
        "def format_data(example):\n",
        "    return {\"text\": example[\"text\"], \"labels\": example[\"label\"]}\n",
        "\n",
        "dataset = dataset.map(format_data)\n",
        "\n",
        "# Define metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = logits.argmax(axis=-1)\n",
        "    return {\"accuracy\": accuracy_score(labels, preds)}\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512\n",
        "    )\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_dataset = tokenized_dataset.remove_columns([\"text\", \"label\"])\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fAyLFLug21n3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Config Trainer\n",
        "# Set up Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=32,\n",
        "        gradient_accumulation_steps=1,\n",
        "        warmup_steps=5,\n",
        "        num_train_epochs=1,\n",
        "        learning_rate=5e-5,\n",
        "        fp16=not is_bfloat16_supported(),\n",
        "        bf16=is_bfloat16_supported(),\n",
        "        logging_steps=1,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        eval_steps=0.10,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=\"outputs\",\n",
        "        report_to=\"none\",\n",
        "    ),\n",
        "    train_dataset=tokenized_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "mE2Q3_XP25Va"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Starting training\n",
        "# Train the model\n",
        "trainer_stats = trainer.train()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wf_i-2i726-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Quick Test\n",
        "from transformers import pipeline\n",
        "\n",
        "sentence1 = \"\"\"\n",
        "This movie was not that great at all.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=model,tokenizer=tokenizer)\n",
        "\n",
        "classifier(sentence1)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jpM75OVv4M_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Deep Testing (Evaluating)\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "\n",
        "# Load the test split of the IMDb dataset\n",
        "test_dataset = load_dataset(\"imdb\", split=\"test\")\n",
        "\n",
        "# Re-use the same formatting and tokenization functions as before\n",
        "def format_data(example):\n",
        "    return {\"text\": example[\"text\"], \"labels\": example[\"label\"]}\n",
        "test_dataset = test_dataset.map(format_data)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_test_dataset = tokenized_test_dataset.remove_columns([\"text\", \"label\"])\n",
        "\n",
        "# Set up a new Trainer for evaluation\n",
        "eval_trainer = Trainer(\n",
        "    model=model,\n",
        "    args=TrainingArguments(\n",
        "        output_dir=\"./evaluation_results\",\n",
        "        report_to=\"none\",\n",
        "    ),\n",
        "    eval_dataset=tokenized_test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Run the evaluation and print the results\n",
        "eval_results = eval_trainer.evaluate()\n",
        "print(f\"Evaluation results: {eval_results}\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kRUfa4lS6YoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Test by reviews\n",
        "# Create a text review to test\n",
        "positive_review = \"This movie was an absolute masterpiece! The acting, direction, and story were perfect.\"\n",
        "negative_review = \"I was incredibly disappointed by this movie. The plot was boring and the ending made no sense.\"\n",
        "\n",
        "# Tokenize the input text\n",
        "inputs_positive = tokenizer(positive_review, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "inputs_negative = tokenizer(negative_review, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "# Ensure the model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Move the inputs to the correct device (GPU if available)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "inputs_positive = {k: v.to(device) for k, v in inputs_positive.items()}\n",
        "inputs_negative = {k: v.to(device) for k, v in inputs_negative.items()}\n",
        "model.to(device)\n",
        "\n",
        "# Get the model's predictions\n",
        "with torch.no_grad():\n",
        "    outputs_positive = model(**inputs_positive)\n",
        "    outputs_negative = model(**inputs_negative)\n",
        "\n",
        "# Interpret the results\n",
        "# The logits correspond to the two labels: 0 (negative) and 1 (positive)\n",
        "positive_prediction = torch.argmax(outputs_positive.logits, dim=-1).item()\n",
        "negative_prediction = torch.argmax(outputs_negative.logits, dim=-1).item()\n",
        "\n",
        "print(f\"Review: '{positive_review}'\")\n",
        "print(f\"Prediction: {'Positive' if positive_prediction == 1 else 'Negative'}\")\n",
        "print(f\"Confidence: {outputs_positive.logits.softmax(dim=-1).max().item()}\")\n",
        "\n",
        "print(f\"\\nReview: '{negative_review}'\")\n",
        "print(f\"Prediction: {'Positive' if negative_prediction == 1 else 'Negative'}\")\n",
        "print(f\"Confidence: {outputs_negative.logits.softmax(dim=-1).max().item()}\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9STDJYLl61ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Save local\n",
        "model.save_pretrained(\"sentim_movies\")\n",
        "tokenizer.save_pretrained(\"sentim_movies\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PBG2f8sx8oPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title login hf\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "S0PhBfQh9Xzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Save to huggingface\n",
        "model.push_to_hub(\"aired/sentim_movies\")\n",
        "tokenizer.push_to_hub(\"aired/sentim_movies\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "KqQGBPm886Cb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}